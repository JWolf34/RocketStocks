{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import csv\n",
    "import os\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import base data\n",
    "\n",
    "QQQ_base = pd.read_csv(r'C:\\Users\\kangb\\OneDrive\\Desktop\\Stock data\\Yahoo Finance\\yfinance data\\QQQ_base.csv')\n",
    "TQQQ_base = pd.read_csv(r'C:\\Users\\kangb\\OneDrive\\Desktop\\Stock data\\Yahoo Finance\\yfinance data\\TQQQ_base.csv')\n",
    "SQQQ_base = pd.read_csv(r'C:\\Users\\kangb\\OneDrive\\Desktop\\Stock data\\Yahoo Finance\\yfinance data\\SQQQ_base.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# collect new data from yfinance, save as csv, then import new data\n",
    "\n",
    "QQQ_new  = yf.download(tickers = \"QQQ\",  # list of tickers\n",
    "            period = \"1d\",         # time period\n",
    "            interval = \"1m\",       # trading interval\n",
    "            prepost = True,       # download pre/post market hours data?\n",
    "            repair = True)         # repair obvious price errors e.g. 100x?\n",
    "QQQ_new.to_csv(r'C:\\Users\\kangb\\OneDrive\\Desktop\\Stock data\\Yahoo Finance\\yfinance data\\QQQ_new.csv')\n",
    "\n",
    "TQQQ_new  = yf.download(tickers = \"TQQQ\",  # list of tickers\n",
    "            period = \"max\",         # time period\n",
    "            interval = \"1m\",       # trading interval\n",
    "            prepost = True,       # download pre/post market hours data?\n",
    "            repair = True)         # repair obvious price errors e.g. 100x?\n",
    "TQQQ_new.to_csv(r'C:\\Users\\kangb\\OneDrive\\Desktop\\Stock data\\Yahoo Finance\\yfinance data\\TQQQ_new.csv')\n",
    "\n",
    "SQQQ_new  = yf.download(tickers = \"SQQQ\",  # list of tickers\n",
    "            period = \"max\",         # time period\n",
    "            interval = \"1m\",       # trading interval\n",
    "            prepost = True,       # download pre/post market hours data?\n",
    "            repair = True)         # repair obvious price errors e.g. 100x?\n",
    "SQQQ_new.to_csv(r'C:\\Users\\kangb\\OneDrive\\Desktop\\Stock data\\Yahoo Finance\\yfinance data\\SQQQ_new.csv')\n",
    "\n",
    "\n",
    "QQQ_new = pd.read_csv(r'C:\\Users\\kangb\\OneDrive\\Desktop\\Stock data\\Yahoo Finance\\yfinance data\\QQQ_new.csv')\n",
    "TQQQ_new = pd.read_csv(r'C:\\Users\\kangb\\OneDrive\\Desktop\\Stock data\\Yahoo Finance\\yfinance data\\TQQQ_new.csv')\n",
    "SQQQ_new = pd.read_csv(r'C:\\Users\\kangb\\OneDrive\\Desktop\\Stock data\\Yahoo Finance\\yfinance data\\SQQQ_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the QQQ_base and QQQ_new dataframes already defined\n",
    "\n",
    "# Merge QQQ_base and QQQ_new on \"Datetime\"\n",
    "merged_df = pd.merge(SQQQ_base, SQQQ_new, on=\"Datetime\", suffixes=(\"_base\", \"_new\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-identical values: 15\n",
      "                       Datetime  Open_base  High_base   Low_base  Close_base  \\\n",
      "149   2023-06-23 06:28:00-04:00  19.800000  19.810000  19.800000   19.810000   \n",
      "324   2023-06-23 09:38:00-04:00  19.990000  20.009899  19.980000   19.996799   \n",
      "377   2023-06-23 10:31:00-04:00  20.000000  20.037901  19.990101   19.997801   \n",
      "397   2023-06-23 10:52:00-04:00  20.084999  20.100000  20.049999   20.059999   \n",
      "699   2023-06-23 15:54:00-04:00  19.940001  19.990000  19.930000   19.985600   \n",
      "1300  2023-06-26 10:11:00-04:00  19.740000  19.770000  19.735001   19.770000   \n",
      "1332  2023-06-26 10:43:00-04:00  20.080000  20.080000  20.040001   20.052099   \n",
      "1640  2023-06-26 15:51:00-04:00  20.705500  20.725000  20.700001   20.700001   \n",
      "2288  2023-06-27 10:54:00-04:00  20.500000  20.510000  20.484200   20.490400   \n",
      "3239  2023-06-28 11:00:00-04:00  19.480000  19.490000  19.470100   19.475000   \n",
      "3416  2023-06-28 13:57:00-04:00  19.795401  19.825701  19.790001   19.815001   \n",
      "3539  2023-06-28 16:00:00-04:00  19.650000  19.670000  19.580000   19.580000   \n",
      "4034  2023-06-29 08:16:00-04:00  19.500000  19.510000  19.500000   19.510000   \n",
      "4608  2023-06-29 18:07:00-04:00  19.800000  19.800000  19.800000   19.800000   \n",
      "4611  2023-06-29 18:10:00-04:00  19.780000  19.780000  19.770000   19.770000   \n",
      "\n",
      "      Adj Close_base  Volume_base  Repaired?_base   Open_new   High_new  \\\n",
      "149        19.810000            0             NaN  19.810000  19.810000   \n",
      "324        19.996799       918803             NaN  20.000000  20.049999   \n",
      "377        19.997801       415179             NaN  20.010000  20.037901   \n",
      "397        20.059999       917521             NaN  20.075001  20.100000   \n",
      "699        19.985600       517895             NaN  19.930000  19.990000   \n",
      "1300       19.770000       880643             NaN  19.760000  19.770000   \n",
      "1332       20.052099       554586             NaN  20.090799  20.100000   \n",
      "1640       20.700001       469221             NaN  20.725401  20.739901   \n",
      "2288       20.490400       196830             NaN  20.529900  20.539900   \n",
      "3239       19.475000       831044             NaN  19.500000  19.510000   \n",
      "3416       19.815001       160628             NaN  19.790001  19.825701   \n",
      "3539       19.580000    123726795             NaN  19.660000  19.670000   \n",
      "4034       19.510000            0             NaN  19.510000  19.510000   \n",
      "4608       19.800000            0             NaN  19.790000  19.800000   \n",
      "4611       19.770000            0             NaN  19.790000  19.790000   \n",
      "\n",
      "        Low_new  Close_new  Adj Close_new  Volume_new  Repaired?_new  \n",
      "149   19.810000  19.810000      19.810000           0            NaN  \n",
      "324   19.980000  19.996799      19.996799      726021            NaN  \n",
      "377   19.990101  19.997801      19.997801      488379            NaN  \n",
      "397   20.049999  20.059999      20.059999      475784            NaN  \n",
      "699   19.930000  19.985600      19.985600      517895            NaN  \n",
      "1300  19.730200  19.770000      19.770000      545369            NaN  \n",
      "1332  20.040001  20.052099      20.052099      554586            NaN  \n",
      "1640  20.700001  20.700001      20.700001      368944            NaN  \n",
      "2288  20.484200  20.490400      20.490400      196830            NaN  \n",
      "3239  19.470100  19.475000      19.475000      831044            NaN  \n",
      "3416  19.790001  19.815001      19.815001      160628            NaN  \n",
      "3539  19.580000  19.580000      19.580000      175822            NaN  \n",
      "4034  19.500000  19.510000      19.510000           0            NaN  \n",
      "4608  19.790000  19.790000      19.790000           0            NaN  \n",
      "4611  19.770000  19.780000      19.780000           0            NaN  \n"
     ]
    }
   ],
   "source": [
    "non_identical_rows = merged_df[merged_df['Open_base'] != merged_df['Open_new']]\n",
    "\n",
    "print(\"Number of non-identical values:\", len(non_identical_rows))\n",
    "print(non_identical_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Open_base</th>\n",
       "      <th>High_base</th>\n",
       "      <th>Low_base</th>\n",
       "      <th>Close_base</th>\n",
       "      <th>Adj Close_base</th>\n",
       "      <th>Volume_base</th>\n",
       "      <th>Repaired?_base</th>\n",
       "      <th>Open_new</th>\n",
       "      <th>High_new</th>\n",
       "      <th>Low_new</th>\n",
       "      <th>Close_new</th>\n",
       "      <th>Adj Close_new</th>\n",
       "      <th>Volume_new</th>\n",
       "      <th>Repaired?_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-22 19:58:00-04:00</td>\n",
       "      <td>366.500</td>\n",
       "      <td>366.540</td>\n",
       "      <td>366.50</td>\n",
       "      <td>366.505</td>\n",
       "      <td>366.505</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>366.500</td>\n",
       "      <td>366.54</td>\n",
       "      <td>366.50</td>\n",
       "      <td>366.505</td>\n",
       "      <td>366.505</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-22 19:59:00-04:00</td>\n",
       "      <td>366.500</td>\n",
       "      <td>366.500</td>\n",
       "      <td>366.40</td>\n",
       "      <td>366.450</td>\n",
       "      <td>366.450</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>366.500</td>\n",
       "      <td>366.50</td>\n",
       "      <td>366.40</td>\n",
       "      <td>366.450</td>\n",
       "      <td>366.450</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-23 04:00:00-04:00</td>\n",
       "      <td>364.880</td>\n",
       "      <td>364.880</td>\n",
       "      <td>364.50</td>\n",
       "      <td>364.600</td>\n",
       "      <td>364.600</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>364.880</td>\n",
       "      <td>364.88</td>\n",
       "      <td>364.50</td>\n",
       "      <td>364.600</td>\n",
       "      <td>364.600</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-06-23 04:01:00-04:00</td>\n",
       "      <td>364.550</td>\n",
       "      <td>364.630</td>\n",
       "      <td>364.55</td>\n",
       "      <td>364.580</td>\n",
       "      <td>364.580</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>364.550</td>\n",
       "      <td>364.69</td>\n",
       "      <td>364.55</td>\n",
       "      <td>364.640</td>\n",
       "      <td>364.640</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-06-23 04:02:00-04:00</td>\n",
       "      <td>364.610</td>\n",
       "      <td>364.610</td>\n",
       "      <td>364.50</td>\n",
       "      <td>364.510</td>\n",
       "      <td>364.510</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>364.620</td>\n",
       "      <td>364.62</td>\n",
       "      <td>364.50</td>\n",
       "      <td>364.510</td>\n",
       "      <td>364.510</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4528</th>\n",
       "      <td>2023-06-29 18:14:00-04:00</td>\n",
       "      <td>363.935</td>\n",
       "      <td>363.950</td>\n",
       "      <td>363.92</td>\n",
       "      <td>363.920</td>\n",
       "      <td>363.920</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>363.935</td>\n",
       "      <td>363.95</td>\n",
       "      <td>363.92</td>\n",
       "      <td>363.920</td>\n",
       "      <td>363.920</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4529</th>\n",
       "      <td>2023-06-29 18:15:00-04:00</td>\n",
       "      <td>363.900</td>\n",
       "      <td>363.940</td>\n",
       "      <td>363.85</td>\n",
       "      <td>363.940</td>\n",
       "      <td>363.940</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>363.900</td>\n",
       "      <td>363.94</td>\n",
       "      <td>363.85</td>\n",
       "      <td>363.940</td>\n",
       "      <td>363.940</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4530</th>\n",
       "      <td>2023-06-29 18:16:00-04:00</td>\n",
       "      <td>363.920</td>\n",
       "      <td>363.980</td>\n",
       "      <td>363.92</td>\n",
       "      <td>363.980</td>\n",
       "      <td>363.980</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>363.920</td>\n",
       "      <td>363.98</td>\n",
       "      <td>363.92</td>\n",
       "      <td>363.980</td>\n",
       "      <td>363.980</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4531</th>\n",
       "      <td>2023-06-29 18:17:00-04:00</td>\n",
       "      <td>363.990</td>\n",
       "      <td>364.030</td>\n",
       "      <td>363.99</td>\n",
       "      <td>364.030</td>\n",
       "      <td>364.030</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>363.990</td>\n",
       "      <td>364.03</td>\n",
       "      <td>363.99</td>\n",
       "      <td>364.030</td>\n",
       "      <td>364.030</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4532</th>\n",
       "      <td>2023-06-29 18:18:00-04:00</td>\n",
       "      <td>364.020</td>\n",
       "      <td>364.025</td>\n",
       "      <td>364.02</td>\n",
       "      <td>364.025</td>\n",
       "      <td>364.025</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>364.020</td>\n",
       "      <td>364.03</td>\n",
       "      <td>364.00</td>\n",
       "      <td>364.030</td>\n",
       "      <td>364.030</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4533 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Datetime  Open_base  High_base  Low_base  Close_base  \\\n",
       "0     2023-06-22 19:58:00-04:00    366.500    366.540    366.50     366.505   \n",
       "1     2023-06-22 19:59:00-04:00    366.500    366.500    366.40     366.450   \n",
       "2     2023-06-23 04:00:00-04:00    364.880    364.880    364.50     364.600   \n",
       "3     2023-06-23 04:01:00-04:00    364.550    364.630    364.55     364.580   \n",
       "4     2023-06-23 04:02:00-04:00    364.610    364.610    364.50     364.510   \n",
       "...                         ...        ...        ...       ...         ...   \n",
       "4528  2023-06-29 18:14:00-04:00    363.935    363.950    363.92     363.920   \n",
       "4529  2023-06-29 18:15:00-04:00    363.900    363.940    363.85     363.940   \n",
       "4530  2023-06-29 18:16:00-04:00    363.920    363.980    363.92     363.980   \n",
       "4531  2023-06-29 18:17:00-04:00    363.990    364.030    363.99     364.030   \n",
       "4532  2023-06-29 18:18:00-04:00    364.020    364.025    364.02     364.025   \n",
       "\n",
       "      Adj Close_base  Volume_base  Repaired?_base  Open_new  High_new  \\\n",
       "0            366.505            0             NaN   366.500    366.54   \n",
       "1            366.450            0             NaN   366.500    366.50   \n",
       "2            364.600            0             NaN   364.880    364.88   \n",
       "3            364.580            0             NaN   364.550    364.69   \n",
       "4            364.510            0             NaN   364.620    364.62   \n",
       "...              ...          ...             ...       ...       ...   \n",
       "4528         363.920            0             NaN   363.935    363.95   \n",
       "4529         363.940            0             NaN   363.900    363.94   \n",
       "4530         363.980            0             NaN   363.920    363.98   \n",
       "4531         364.030            0             NaN   363.990    364.03   \n",
       "4532         364.025            0             NaN   364.020    364.03   \n",
       "\n",
       "      Low_new  Close_new  Adj Close_new  Volume_new  Repaired?_new  \n",
       "0      366.50    366.505        366.505           0            NaN  \n",
       "1      366.40    366.450        366.450           0            NaN  \n",
       "2      364.50    364.600        364.600           0            NaN  \n",
       "3      364.55    364.640        364.640           0            NaN  \n",
       "4      364.50    364.510        364.510           0            NaN  \n",
       "...       ...        ...            ...         ...            ...  \n",
       "4528   363.92    363.920        363.920           0            NaN  \n",
       "4529   363.85    363.940        363.940           0            NaN  \n",
       "4530   363.92    363.980        363.980           0            NaN  \n",
       "4531   363.99    364.030        364.030           0            NaN  \n",
       "4532   364.00    364.030        364.030           0            NaN  \n",
       "\n",
       "[4533 rows x 15 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QQQ (20230623133500000 _ 20230622145900000).csv\n",
      "QQQ (20230627095800000 _ 20230621123400000).csv\n",
      "QQQ (20230627145900000 _ 20230622111700000).csv\n",
      "SQQQ (20230623135100000 _ 20230622083000000).csv\n",
      "SQQQ (20230627095700000 _ 20230621123300000).csv\n",
      "SQQQ (20230627145900000 _ 20230622111300000).csv\n",
      "TQQQ (20230622145900000 _ 20230621145900000).csv\n",
      "TQQQ (20230623135400000 _ 20230622091600000).csv\n",
      "TQQQ (20230627095600000 _ 20230622084200000).csv\n",
      "TQQQ (20230627145900000 _ 20230622111300000).csv\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\Users\\kangb\\OneDrive\\Desktop\\Stock data\\Yahoo Finance'\n",
    "file_paths = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "\n",
    "qqq_list = []\n",
    "tqqq_list = []\n",
    "sqqq_list = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    file_name = os.path.basename(file_path)  # Extract the filename from the file path\n",
    "    if file_name.startswith('QQQ'):\n",
    "        qqq_list.append(file_path)\n",
    "    elif file_name.startswith('TQQQ'):\n",
    "        tqqq_list.append(file_path)\n",
    "    elif file_name.startswith('SQQQ'):\n",
    "        sqqq_list.append(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\kangb\\\\OneDrive\\\\Desktop\\\\Stock data\\\\Yahoo Finance\\\\QQQ (20230623133500000 _ 20230622145900000).csv',\n",
       " 'C:\\\\Users\\\\kangb\\\\OneDrive\\\\Desktop\\\\Stock data\\\\Yahoo Finance\\\\QQQ (20230627095800000 _ 20230621123400000).csv',\n",
       " 'C:\\\\Users\\\\kangb\\\\OneDrive\\\\Desktop\\\\Stock data\\\\Yahoo Finance\\\\QQQ (20230627145900000 _ 20230622111700000).csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qqq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge QQQ files\n",
    "qqq_merged = pd.DataFrame()\n",
    "for file_path in qqq_list:\n",
    "    df = pd.read_csv(file_path)\n",
    "    qqq_merged = pd.concat([qqq_merged, df], ignore_index=True)\n",
    "qqq_merged.drop_duplicates(inplace=True)\n",
    "\n",
    "# Check for duplicate values in \"Date\" column\n",
    "if qqq_merged['Date'].duplicated().any():\n",
    "    print(\"Duplicate values found in the 'Date' column of merged QQQ CSV.\")\n",
    "\n",
    "# Check for missing values in \"Date\" column\n",
    "start_time = datetime.strptime(qqq_merged['Date'].iloc[0], \"%H:%M\")\n",
    "for i in range(1, len(qqq_merged)):\n",
    "    current_time = datetime.strptime(qqq_merged['Date'].iloc[i], \"%H:%M\")\n",
    "    expected_time = start_time + timedelta(minutes=i)\n",
    "    if current_time != expected_time:\n",
    "        print(\"Missing value found in the 'Date' column of merged QQQ CSV.\")\n",
    "        break\n",
    "\n",
    "#qqq_merged.to_csv('/path/to/folder/merged_QQQ.csv', index=False)\n",
    "\n",
    "# Merge TQQQ files\n",
    "tqqq_merged = pd.DataFrame()\n",
    "for file_path in tqqq_list:\n",
    "    df = pd.read_csv(file_path)\n",
    "    tqqq_merged = pd.concat([tqqq_merged, df], ignore_index=True)\n",
    "tqqq_merged.drop_duplicates(inplace=True)\n",
    "\n",
    "# Check for duplicate values in \"Date\" column\n",
    "if tqqq_merged['Date'].duplicated().any():\n",
    "    print(\"Duplicate values found in the 'Date' column of merged TQQQ CSV.\")\n",
    "\n",
    "# Check for missing values in \"Date\" column\n",
    "start_time = datetime.strptime(tqqq_merged['Date'].iloc[0], \"%H:%M\")\n",
    "for i in range(1, len(tqqq_merged)):\n",
    "    current_time = datetime.strptime(tqqq_merged['Date'].iloc[i], \"%H:%M\")\n",
    "    expected_time = start_time + timedelta(minutes=i)\n",
    "    if current_time != expected_time:\n",
    "        print(\"Missing value found in the 'Date' column of merged TQQQ CSV.\")\n",
    "        break\n",
    "\n",
    "#tqqq_merged.to_csv('/path/to/folder/merged_TQQQ.csv', index=False)\n",
    "\n",
    "# Merge SQQQ files\n",
    "sqqq_merged = pd.DataFrame()\n",
    "for file_path in sqqq_list:\n",
    "    df = pd.read_csv(file_path)\n",
    "    sqqq_merged = pd.concat([sqqq_merged, df], ignore_index=True)\n",
    "sqqq_merged.drop_duplicates(inplace=True)\n",
    "\n",
    "# Check for duplicate values in \"Date\" column\n",
    "if sqqq_merged['Date'].duplicated().any():\n",
    "    print(\"Duplicate values found in the 'Date' column of merged SQQQ CSV.\")\n",
    "\n",
    "# Check for missing values in \"Date\" column\n",
    "start_time = datetime.strptime(sqqq_merged['Date'].iloc[0], \"%H:%M\")\n",
    "for i in range(1, len(sqqq_merged)):\n",
    "    current_time = datetime.strptime(sqqq_merged['Date'].iloc[i], \"%H:%M\")\n",
    "    expected_time = start_time + timedelta(minutes=i)\n",
    "    if current_time != expected_time:\n",
    "        print(\"Missing value found in the 'Date' column of merged SQQQ CSV.\")\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stocks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65a0c1c9ac4c30e764a0427d9f5bcee3c05e72d34b20cd4889b65ecddf5030c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
